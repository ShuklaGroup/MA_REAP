import os
from collections import Counter

import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min
# from scipy.io import mmread
from utils import save_pickle, run_monte_carlo_traj, num_clusters, \
    spawn_trajectories_MA


def clustering(state_sequences, mapping, n_clusters=None, max_frames=1e5):
    '''
    Clusters all (or a representative subset) of the frames in trajectories using KMeans. Returns clustering object, which will be used to select the 
    least counts clusters. The selected subset of the total frames are also returned.
    
    Args
    -------------
    state_sequences (list[list[np.ndarray]]): trajectories collected so far (in terms of MSM states indices). 
        They should be accessed as trajectories[ith_agent][jth_trajectory].
    mapping (Callable): maps an MSM microstate to CV-space.
    n_clusters (int), default None: number of clusters to use for KMeans. If None, a heuristic is used to approximate the number of clusters needed.
    max_frames (int), default 1e5: maximum number of frames to use in the clustering step. If set to 0 or None, all frames are used.
    
    Returns
    -------------
    KMeans (sklearn.cluster.KMeans): fitted KMeans clustering object.
    X (np.ndarray): array of shape (max_frames,) containing the subset of the data (in terms of MSM states indices) used for clustering.
    '''

    # Put frames in format that is usable for KMeans

    total_frames = 0
    trajectory = []  # All frames
    for a, agent_trajs in enumerate(state_sequences):
        for traj in agent_trajs:
            total_frames += len(traj)
            trajectory.append(traj)

    trajectory = np.concatenate(trajectory)

    # Downsample number of points
    if (not max_frames) or (total_frames <= max_frames):
        X = trajectory

    elif total_frames > max_frames:
        max_frames = int(max_frames)
        rng = np.random.default_rng()
        rand_indices = rng.choice(len(trajectory), max_frames, replace=False)
        X = trajectory[rand_indices]

    # Use n_clusters = number of states discovered (and present in random sample)
    if (n_clusters is None):
        n_clusters = num_clusters(X)

    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=3).fit(mapping(X))

    return kmeans, X


def select_least_counts(kmeans, X, mapping, n_select=50, stakes_method='percentage'):
    '''
    Select candidate clusters for new round of simulations based on least counts policy.
    
    Args
    -------------
    kmeans (sklearn.cluster.KMeans): KMeans clustering object fitted on X.
    X (np.ndarray): array of shape (max_frames,) containing the subset of the data (in terms of MSM states indices) used for clustering.
    agent_idx (np.ndarray): array of shape (n_frames,) indicating which agent originated each frame.
    n_agents (int): number of agents.
    n_select (int), default 50: how many candidates to select based on least counts policy.
    
    Returns
    -------------
    central_frames (np.ndarray): array of shape (n_select,). Frames in X that are closest to the center of each candidate (in terms of MSM states).
    central_frames_indices (np.ndarray): array of shape (n_select,). Indices of the frames in X that are closest to the center of each candidate.
    agent_stakes (np.ndarray): array of shape (n_agents, n_select). Entry agent_stakes[i, j] indicates the fraction of frames from 
        candidate j that were generated by agent i.
    '''

    # Select n_select candidates via least counts
    counts = Counter(kmeans.labels_)
    least_counts = np.asarray(counts.most_common()[::-1][:n_select])[:, 0]  # Which clusters contain lowest populations

    # Find frames closest to cluster centers of candidates
    least_counts_centers = kmeans.cluster_centers_[least_counts]
    central_frames_indices, _ = pairwise_distances_argmin_min(least_counts_centers, mapping(X))
    central_frames = X[central_frames_indices]

    return central_frames, central_frames_indices


def run_trial(msm, initial_states, epochs, output_dir='./', output_prefix='', **kwargs):
    '''
    Runs a trial of MA REAP with standard Euclidean distance rewards.
    
    Args
    -------------
    msm (pyemma.msm.models.msm.MSM): Markov State Model that will determine the kinetics of the simulation.
    initial_states (list[int]): starting states for simulations.
    epochs (int): specifies for how many epochs to run a trial.
    output_dir (str): folder where to store the results (it will be created in current working directory if it does not exist).
    output_prefix (str): common prefix for all log files.
    **kwargs: used to specify model hyperparameters. Must include following keys:
        num_spawn (int): number of total trajectories to spawn per epoch.
        n_select (int): number of least-count candidates selected per epoch.
        traj_len (int): length of each trajectory ran.
        n_features (int): number of collective variables.
        max_frames (int): maximum number of frames to use in clustering steps (take random subsample to accelerate testing).
        mapping (callable): mapping from MSM state to CV space.
        
    Returns
    -------------
    None. Results are saved to output_dir.
    '''

    # Create directory
    if not os.path.isdir(output_dir):
        os.mkdir(output_dir)

    # Step 1: define some hyperparameters and initialize arrays
    n_select = kwargs['n_select']  # Number of least-count candidates selected per epoch
    # All trajectories will be stored in terms of MSM states indices and converted to CV space when required using map_state_to_coordinates
    state_sequences = [[] for _ in range(len(initial_states))]
    epochs = epochs
    traj_len = kwargs['traj_len']
    max_frames = kwargs['max_frames']
    mapping = kwargs['mapping']

    # Logs
    selected_structures_log = []

    # Step 2: collect some initial data
    n_clusters = 0
    while n_clusters < n_select:  # Make sure to have enough states before running REAP
        for i in range(len(initial_states)):
            state_seq = run_monte_carlo_traj(msm, init_state=initial_states[i], n_steps=traj_len)
            state_sequences[i].append(state_seq)
        n_clusters = num_clusters(np.concatenate(np.concatenate(state_sequences)))

    # Step 3: run simulations
    for e in range(epochs):
        print("Running epoch: {}/{}".format(e + 1, epochs), end='\r')

        # Clustering
        kmeans, X = clustering(state_sequences, mapping, n_clusters=None, max_frames=max_frames)

        # Select candidates
        central_frames, central_frames_indices = select_least_counts(kmeans, X, mapping, n_select=n_select)

        # Save log
        selected_structures_log.append(central_frames)

        # Spawn trajectories
        state_sequences = spawn_trajectories_MA(state_sequences, msm, central_frames,
                                                np.zeros(len(central_frames)).astype(int), traj_len=traj_len)

        if ((e + 1) % 10 == 0):  # Plotting range applies to Src Kinase example
            print("Running epoch: {}/{}".format(e + 1, epochs))

            CVs = mapping(np.concatenate(state_sequences[0]))
            plt.scatter(CVs[:, 0], CVs[:, 1], s=10)
            plt.xlim([0, 1])
            plt.ylim([0.3, 1.8])
            plt.savefig(os.path.join(output_dir, output_prefix + 'landscape_epoch_{}.png'.format(e)), dpi=150)
            plt.close()

    save_pickle(state_sequences, os.path.join(output_dir, output_prefix + 'trajectories.pickle'))
    save_pickle(selected_structures_log, os.path.join(output_dir, output_prefix + 'selected_structures_log.pickle'))
